\chapter{Empirical Analysis}

\section{Implementation}

\subsection{Execution environment}
The empirical analysis is based on the output of executing different
implementations on a machine with the following specifications:

%\begin{table}[!ht]
\begin{tabular}{|l|l|}
\hline
CPU & Intel\textregistered Core\texttrademark i5-2400 CPU @ 3.10GHz $\times$ 4
\\
\hline
Memory & Hynix/Hyundai 2048 MB DDR3 RAM @ 1333 MHz $\times$ 2 \\
\hline
Operating System & Ubuntu 12.10 64-bit \\
\hline
\end{tabular}
%\end{table}

\subsection{Implemented operations}

I have implemented Node Copying and Rollback for a doubly linked list. Both
implementations support the following operations:

\begin{description}

  \item[$\textsc{insert}(i,d)$] Inserts an element with data $d$ at index $i$.

  \item[$\textsc{modify}(i,d)$] Modifies the data of the element at index $i$ to
  $d$.

  \item[$\textsc{remove}(i)$] Removes the element at index $i$.

\end{description}

These first three represent the usual operations available on a linked list,
with bulk operation friendly parameters (conventional linked list
implementations take a pointer to a node instead of an index). The difference is
that they create a new version of the data structure.

\begin{description}

  \item[$\textsc{head}(v)$] Returns the head node of the list at version
  $v$.

  \item[$\textsc{size}(v)$] Returns the size of the list at version $v$.

\end{description}

These next two are also usually available in a linked list implementation, but
these variants take the number of a version $v$ from which to return the
information.

\begin{description}

  \item[$\textsc{access}(v,i)$] Returns the value of the element at index $i$ in
  version $v$.

  \item[$\textsc{num\_versions}()$] Returns the total number of versions.

\end{description}

These last two are implemented for the convenience of testing bulk usage of the
data structure.

Let the operations $\textsc{insert}(i,d)$, $\textsc{modify}(i,d)$,
$\textsc{remove}(i)$ and $\textsc{access}(v,i)$ be the ones benchmarked.

\subsection{Implemented usage scenarios}

In bemchmarking the performance of the approaches in practice, we will look at
how they perform under various usage scenarios.

When either of the two approaches are to be used in practice, one can imagine
different usage scenarios:

\begin{description}

  \item[Uniformly random] The operations are executed in random order with no
  particular pattern. They may be weighted such that there is different
  probability for choosing different operations.

  \item[Sequential] The different types of operations are executed in sequences,
  e.g. first a number of \textsc{insert} operations, then a number of
  \textsc{access} operations.

%   \item[Worst-case] With certain usage patterns, one implementation may perform
%   significantly worse than average.

\end{description}


\subsection{Program executable}

The above scenarios have been implemented in the program \texttt{msc}, which
accepts the following arguments:

\begin{description}

  \item[\texttt{-\@{}-count}/\texttt{-c \{num\}}] Total number of operations to carry
  out (default: 1000).

  \item[\texttt{-\@{}-randomize-operations}] If passed, applies the operations
  chosen at random between the four types. Otherwise, insertions are applied
  first, then modifications, then removals, then access operations (default:
  off).

  \item[\texttt{-\@{}-rollback-eliminate-reorder}/\texttt{-l}] Will use the Rollback
  implementation with elimination of superfluous operations and operations
  reordering for applying the operations (default).

  \item[\texttt{-\@{}-rollback-blackbox}/\texttt{-r}] Will use the black-box
  Rollback implementation for applying the operations (default).

  \item[\texttt{-\@{}-node-copying}/\texttt{-p}] Will use the Node
  Copying implementation for applying the operations.

  \item[\texttt{-\@{}-max-snapshot-dist}/\texttt{-d \{num\}}] Maximum number of
  operations between snapshots (default: 65, applies only to the Rollback
  implementation).

  \item[\texttt{-\@{}-max-num-snapshots}/\texttt{-m \{num\}}] Maximum number of
  snapshots before adaptive fallback is carried out (default: 2000, applies only to the Rollback
  implementation).

  \item[\texttt{-\@{}-store-results}/\texttt{-s}] If set, will store results in
  an SQLite database file ``sqlite.db''.

\end{description}

\section{Results}

I have run a series of experiments with various combinations of program
arguments in order to determine the performance of each implementation.

If the \texttt{-\@{}-head-only} argument is given, the index passed to
the operations is 0. Otherwise, the index is randomly selected from the range
$[0..N[$ where $N$ is the number of elements in the list. As for the
\textsc{access} operations, the version is randomly chosen between the versions
which exist when the operation is run.

The sequential scenario is tested by first running a bulk of \textsc{insert}
operations, then a bulk of \textsc{modify} operations, then a bulk of
\textsc{remove} operations and finally a bulk of \textsc{access} operations. The
bulks are of the same size, i.e. an equal fraction of the \texttt{count}
argument.

The randomized scenario is simulated by running a pseudo-randomly selected
operation with equal probability, except if the operation is illegal (such as
modifying or removing from an empty list) or is irrelevant (accessing an element
from a version where the list is empty).

\subsection{Graphs}

In the following graphs, all data points are averages over 10 runs with
identical parameters, each representing the duration spent on the respective
operations. The Y error bars indicate $\pm 1.96$ times the standard deviation,
i.e. a 95\% confidence interval.
% This is useful especially with smaller operation counts, as the data points
% tend to be farther from each other when plotted on logarithmic axes. With the
% visible overlap of the confidence intervals, such differences in data point Y
% values can be better explained.

The following findings are based on inspecting the results of the experiments by
analyzing the graphs and the underlying data:

\begin{itemize}
  \item Node Copying is up to an order of magnitude faster than Rollback
  when it comes to accessing the head of a version --- regardless of usage
  scenario. See figure \ref{fig:access-duration}.

  \item Rollback is not significantly faster at insertions at the head of a list
  --- even in the sequential usage scenario. In fact, in the pseudo-random usage
  scenario, it gets increasingly slower per changing operation (insert, modify,
  remove) operation. See figure \ref{fig:insert-duration}.

  \item When inserting at a random index in the list, however, Rollback is about
  half an order of magnitude faster than Node Copying at insertions in the
  sequential usage scenario. In the randomized scenario, it is less than half an
  order of magnitude faster. See figure \ref{fig:insert-duration}.

  \item Accessing a random element from the list is still much faster with Node
  Copying than with Rollback. See figure \ref{fig:access-duration}.

  \item Rollback \emph{without} elimination of superfluous operations and
  reordering is faster at smaller operation counts, but becomes more costly
  after about X operations.

\end{itemize}


\begin{figure}[!htb]
  \center
  \includegraphics[width=.8\textwidth]%
  {figures/graphs/access-duration-vs-count-head-only.pdf}
  \includegraphics[width=.8\textwidth]%
  {figures/graphs/access-duration-per-op-vs-count-head-only.pdf}

  \caption{Comparison of implementations and scenarious for various operation
  counts. Note how the Node Copying method keeps an approximately constant
  overhead factor per operation, whereas the Rollback method eventually hits the
  upper limit for full copies, and access time increases. It is reached faster
  in the sequential scenario since the full copies are larger.}

  \label{fig:access-duration}
\end{figure}

\begin{figure}[!htb]
  \center
  \includegraphics[width=.8\textwidth]%
  {figures/graphs/insert-duration-vs-count-head-only.pdf}
  \includegraphics[width=.8\textwidth]%
  {figures/graphs/insert-duration-per-op-vs-count-head-only.pdf}

  \caption{Comparison of implementations and scenarious for various operation
  counts. Note how the Node Copying method keeps an approximately constant
  overhead factor per operation, whereas the Rollback method eventually hits the
  upper limit for full copies, and access time increases. It is reached faster
  in the sequential scenario since the full copies are larger.}

  \label{fig:insert-duration}
\end{figure}

\begin{figure}[!htb]
  \center
  \includegraphics[width=.8\textwidth]%
  {figures/graphs/rollbacks-access-duration-vs-count.pdf}
  \includegraphics[width=.8\textwidth]%
  {figures/graphs/rollbacks-access-duration-per-op-vs-count.pdf}

  \caption{Comparison of rollback implementations. Notice how the black-box
  Rollback implementation is almost an order of magnitude faster than the
  implementation with elimination of superfluous operations and operations
  reordering.}

  \label{fig:rollback-comparison}
\end{figure}

